# Monitoring Consumer groups processing using custom metrics

**Authors:** 

- @yaronpri is a Principal Consultant in EMEA &
- [@chgeuer](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/1419878) and [@yodobrin](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/1306386) are Principal Customer Engineers in the Growth & Innovation team.

## Use Case

When using Azure Event Hub, it is important to monitor the 'lag' of the consumer group. 'Lag' refers to the amount of messages events that have not yet been processed within a consumer group. The larger the lag, the more the consumer group is "falling behind". Monitoring this property can help identifying overloaded consuming applications: Increasing lag indicates that the consuming application is not able to keep up with the load of the event hub.

In a queue-based system (such as Azure Storage queues or Azure Service Bus), the 'lag' would correspond to the queue length, i.e. the number of unprocessed messages.

## High Level Solution Approach

Azure Monitor supports [custom metrics](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-custom-overview), i.e. emitting a custom metric to an existing Azure resource, such as an Event Hubs instance. This allows users to enrich their Azure Monitor dashboards, and build richer queries. In this solution, we use a dockerized .NET application to augment an Azure Event Hubs instance with the per-consumer group lag, allowing the customers to closely monitor the workload of the Event Hubs consumers. 

The solution periodically scans the checkpoints, created by the Event Hubs SDK in blob storage, to calculate the lag against the different Event Hubs partitions. The solution continuously sends these deltas as custom metrics towards Azure Monitor, alongside with the event hub name and partition id, and consumer group name. 

These metrics can then be presented as part of the metrics of the Event Hubs instance:

![yodobrin_0-1675770347464.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439488i2F34CF372A394207/image-size/large?v=v2&px=999)

You could also use split by partition ID, consumer group or event hub instance name.

![yodobrin_2-1675770631644.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439491i8FD45CC7C103B109/image-size/large?v=v2&px=999)

In the above example, we could see that a few of the partitions are handling the load better than others.

## How does it work?

Consider this diagram:

![design.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439492i15FC927B4056963C/image-size/large?v=v2&px=999)

Both producers & consumers can follow this [QuickStart](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-dotnet-standard-getstarted-send?tabs=passwordless%2Croles-azure-portal).

The application (deployed as Azure Container App) will iterate over the consumer groups and for each partition will calculate the lag by subtracting the sequence number from the last enqueued sequence number, these values are part of the information available through the event hub SDK. It will then send these calculations as custom metrics to the event hub control plain using REST calls.

## Securely connecting to the backend

The application continuously monitors the lag between events in the EventHubs partitions and the recorded state in Azure blob storage, and emits the delta towards Azure Monitor, i.e. it reads from Event Hubs and Storage, and writes to Azure Monitor. The application connects to all three services using Azure AD authentication. Azure AD tokens usually have a token lifetime of an hour, i.e. for continuous service usage, such access tokens must be refreshed at regular intervals.

- For blob storage access, the application uses the regular .NET storage. The SDK, using the `BlobContainerClient`, handles access token refresh internally on-demand. 
- For EventHub access, the application uses both the EventHub SDK (the `EventHubConsumerClient` class), and plain REST calls, to retrieve the number of partitions, the list of consumer groups, and the concrete partition properties. 
- To emit metrics to Azure Monitor, the application directly calls the Azure Monitor metric store using the [REST API](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-store-custom-rest-api).

As a result, for both EventHub and Azure Monitor, we continuously need a valid access token. The application's  [`TokenStore.RefreshCredentialOnDemand`](https://github.com/Azure-Samples/eventhub-custom-metrics-emitter/blob/ce0eac19acdc7e6c5d7cc540adf7247a4d222b8b/src/emitters/EmitterHelper.cs#L140) method locally keeps a fresh set of access tokens around (and refreshes them on-demand, i.e. around 5 minutes prior expiry), so continues access to the backing services is ensured.

## Whats included in the solution?

We provide source code and deployment bicep scripts, which will create the solution with all required settings. For step by step instructions on how to deploy the solution, please refer to our repository [here](https://github.com/Azure-Samples/eventhub-custom-metrics-emitter).