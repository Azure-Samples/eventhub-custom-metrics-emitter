# Monitoring Consumer groups processing using custom metrics

**Authors:** 

- @yaronpri is a Principal Consultant in EMEA &
- [@chgeuer](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/1378780) and [@yodobrin](https://techcommunity.microsoft.com/t5/user/viewprofilepage/user-id/1306386) are Principal Customer Engineers in the Growth & Innovation team.

## Use Case

When using Azure Event Hub, it is important to monitor the lag of the consumer group. A 'lag' is the number of events that have been sent to the event hub but have not yet been processed by the consumer group. This is important to monitor as it can indicate if the consuming applications are able to address the load of the event hub. If the lag is increasing, it may indicate that the consuming applications are not able to keep up with the load of the event hub.

## High Level Solution Approach

The main idea is to leverage the concept of [custom metrics](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-custom-overview) in Azure monitor, allowing users to build dashboards and query within Azure Monitor. A periodic scan of the checkpoints will enable the calculation of the lag.

The solution will send these values (lag) as custom metrics together with the consumer group name, event hub name and partition id. These metrics can will be presented as part of the metrics of the event hub.

![yodobrin_0-1675770347464.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439488i2F34CF372A394207/image-size/large?v=v2&px=999)

You could also use split by partition, consumer group or eventhub name.

![yodobrin_2-1675770631644.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439491i8FD45CC7C103B109/image-size/large?v=v2&px=999)

In the above example, we could see that a few of the partitions are handling the load better than others.

## How does it work?

Consider this diagram:

![design.png](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/439492i15FC927B4056963C/image-size/large?v=v2&px=999)

Both producers & consumers can follow this [QuickStart](https://learn.microsoft.com/en-us/azure/event-hubs/event-hubs-dotnet-standard-getstarted-send?tabs=passwordless%2Croles-azure-portal).

The application (deployed as Azure Container App) will iterate over the consumer groups and for each partition will calculate the lag by subtracting the sequence number from the last enqueued sequence number, these values are part of the information available through the event hub SDK. It will then send these calculations as custom metrics to the event hub control plain using REST calls.

## Securely connecting to the backend

The application continuously monitors the lag between events in the EventHubs partitions and the recorded state in Azure blob storage, and emits the delta towards Azure Monitor, i.e. it reads from Event Hubs and Storage, and writes to Azure Monitor. The application connects to all three services using Azure AD authentication. Azure AD tokens usually have a token lifetime of an hour, i.e. for continuous service usage, such access tokens must be refreshed at regular intervals.

- For blob storage access, the application uses the regular .NET storage. The SDK, using the `BlobContainerClient`, handles access token refresh internally on-demand. 
- For EventHub access, the application uses both the EventHub SDK (the `EventHubConsumerClient` class), and plain REST calls, to retrieve the number of partitions, the list of consumer groups, and the concrete partition properties. 
- To emit metrics to Azure Monitor, the application directly calls the Azure Monitor metric store using the [REST API](https://learn.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-store-custom-rest-api).

As a result, for both EventHub and Azure Monitor, we continuously need a valid access token. The application's  [`TokenStore.RefreshCredentialOnDemand`](https://github.com/Azure-Samples/eventhub-custom-metrics-emitter/blob/ce0eac19acdc7e6c5d7cc540adf7247a4d222b8b/src/emitters/EmitterHelper.cs#L140) method locally keeps a fresh set of access tokens around (and refreshes them on-demand, i.e. around 5 minutes prior expiry), so continues access to the backing services is ensured.

